{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4.2: Prompt Chaining\n",
    "\n",
    "Building on the simple agent introduced in [Level 1](4.1_tool_calling.ipynb), this tutorial continues the agent-focused section of our series by introducing techniques that make the agent smarter and more autonomous: **Prompt Chaining** and the **ReAct (Reasoning + Acting) framework**. These approaches allow the agent to complete multi-step tasks, dynamically choose tools, and adjust its behavior based on context.\n",
    "\n",
    "- **Prompt Chaining** connects multiple prompts into a coherent sequence, allowing the agent to maintain context and perform multi-step reasoning across tool invocations. \n",
    "- **ReAct Agent** combines reasoning and acting steps in a loop, enabling the agent to make decisions, use tools dynamically, and adapt based on intermediate results. \n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, you'll explore three agent configurations:\n",
    "1. **Simple Agent (Baseline)** – Uses a single web search tool.\n",
    "2. **Prompt Chaining** – Performs structured, multi-step reasoning by chaining prompts and responses.\n",
    "3. **ReAct Agent** – Dynamically plans and executes actions using a loop of reasoning and tool use.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before starting this notebook, ensure that you have:\n",
    "- Followed the instructions in the [Setup Guide](./3_Llama_Stack.ipynb) notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "from llama_stack_client.lib.agents.react.tool_parser import ReActOutput\n",
    "\n",
    "from src.client_tools import get_pod_log\n",
    "from src.lab import get_agent, run_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will initialize our environment as described in detail in our [\"Llama Stack\" notebook](./3_Llama_Stack.ipynb). Please refer to it for additional explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt chaining with websearch tool and client tool\n",
    "\n",
    "In this section, we demonstrate a more sophisticated use case that combines the use of two tools: location detection and web search.\n",
    "\n",
    "1. **Automatic Location Detection**: Use the `get_location` client tool (have a look in the src folder `client_tools.py`) to automatically determine the user's current location.\n",
    "2. **Contextual Search**: Leverage the detected location to formulate the correct websearch query.\n",
    "\n",
    "For example, when a user asks \"Are there any weather-related risks in my area that could disrupt network connectivity or system availability?\", the agent will:\n",
    "- First detect the user's current location using `get_location`.\n",
    "- Then use that location to search for nearby weather-related risks.\n",
    "- Finally, present a comprehensive response.\n",
    "\n",
    "This demonstrates how the builtin websearch tool and custom client tools can work together to provide intelligent, context-aware responses without requiring explicit location input from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "    You are a helpful assistant.\n",
    "    When a user asks about logs from a pod, you MUST use the get_pod_log tool.\"\"\"\n",
    "#    When a user asks for general information, you MUST use the websearch tool.\n",
    "#\"\"\"\n",
    "\n",
    "agent = get_agent(instructions, (get_pod_log, 'builtin::websearch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_name = 'java-app-build-iyyx5z-build-pod'\n",
    "namespace = 'demo-application'\n",
    "container_name = 'step-s2i-build'\n",
    "\n",
    "user_prompts = [\n",
    "    f\"Retrieve the logs of the {container_name} container within the {pod_name} pod in namespace {namespace}.\",\n",
    "    \"Provide a short summary of these logs and troubleshooting recommendations in bullet points.\"\n",
    "]\n",
    "run_session(agent, 'prompt-chaining-session', user_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
